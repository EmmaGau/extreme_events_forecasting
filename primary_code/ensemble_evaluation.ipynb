{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.ticker as mticker\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_files = [\"/home/egauillard/extreme_events_forecasting/earthfomer_mediteranean/src/model/experiments/earthformer_era_20240812_172634_tp_coarse_input_fine_target/inference_plots/all_predictions.nc\",\n",
    "                    \"/home/egauillard/extreme_events_forecasting/earthfomer_mediteranean/src/model/experiments/earthformer_era_20240814_102829_2005_coarse_input_fine_target_45/inference_plots/all_predictions.nc\"\n",
    "                    ]\n",
    "\n",
    "climatology_file = \"/home/egauillard/extreme_events_forecasting/earthfomer_mediteranean/src/model/experiments/earthformer_era_20240812_171128_tp_every_fine/inference_plots/all_climatology.nc\"\n",
    "ground_truth_file = \"/home/egauillard/extreme_events_forecasting/earthfomer_mediteranean/src/model/experiments/earthformer_era_20240812_171128_tp_every_fine/inference_plots/all_ground_truths.nc\"\n",
    "entire_era_file = \"/home/egauillard/extreme_events_forecasting/earthfomer_mediteranean/src/model/experiments/earthformer_era_20240814_102829_2005_coarse_input_fine_target_45/1940_2024_target.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/egauillard/extreme_events_forecasting/earthfomer_mediteranean/src/model/experiments/earthformer_era_20240814_102829/1940_2024_target.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/extreme_events_forecasting/extreme_events_env/lib/python3.11/site-packages/xarray/backends/file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/extreme_events_forecasting/extreme_events_env/lib/python3.11/site-packages/xarray/backends/lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/home/egauillard/extreme_events_forecasting/earthfomer_mediteranean/src/model/experiments/earthformer_era_20240814_102829/1940_2024_target.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '9f7b2f66-c9f3-4eaa-8605-3e4c663b7e62']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 295\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# Usage remains the same\u001b[39;00m\n\u001b[1;32m    292\u001b[0m save_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./evaluation_results\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 295\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[43mModelEvaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclimatology_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentire_era_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mcalculate_scores()\n",
      "Cell \u001b[0;32mIn[44], line 11\u001b[0m, in \u001b[0;36mModelEvaluation.__init__\u001b[0;34m(self, prediction_files, ground_truth_file, climatology_file, save_dir, entire_era_file)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mground_truth_dataset \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(ground_truth_file)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclimatology_dataset \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(climatology_file)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mera_entire_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentire_era_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m=\u001b[39m save_dir\n\u001b[1;32m     13\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(save_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/extreme_events_forecasting/extreme_events_env/lib/python3.11/site-packages/xarray/backends/api.py:572\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    561\u001b[0m     decode_cf,\n\u001b[1;32m    562\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    569\u001b[0m )\n\u001b[1;32m    571\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 572\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    579\u001b[0m     backend_ds,\n\u001b[1;32m    580\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    591\u001b[0m )\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/extreme_events_forecasting/extreme_events_env/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:644\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]  # allow LSP violation, not supporting **kwargs\u001b[39;00m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    625\u001b[0m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike[Any] \u001b[38;5;241m|\u001b[39m BufferedIOBase \u001b[38;5;241m|\u001b[39m AbstractDataStore,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m     autoclose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    642\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[1;32m    643\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 644\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mNetCDF4DataStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m~/extreme_events_forecasting/extreme_events_env/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:407\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    401\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    402\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[1;32m    403\u001b[0m )\n\u001b[1;32m    404\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    405\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    406\u001b[0m )\n\u001b[0;32m--> 407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/extreme_events_forecasting/extreme_events_env/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:354\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m~/extreme_events_forecasting/extreme_events_env/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:416\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/extreme_events_forecasting/extreme_events_env/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:410\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_nc4_require_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/sw/arch/RHEL8/EB_production/2023/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/extreme_events_forecasting/extreme_events_env/lib/python3.11/site-packages/xarray/backends/file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m~/extreme_events_forecasting/extreme_events_env/lib/python3.11/site-packages/xarray/backends/file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2470\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2107\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/egauillard/extreme_events_forecasting/earthfomer_mediteranean/src/model/experiments/earthformer_era_20240814_102829/1940_2024_target.nc'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class ModelEvaluation:\n",
    "    def __init__(self, prediction_files, ground_truth_file, climatology_file, save_dir, entire_era_file):\n",
    "        self.prediction_datasets = [xr.open_dataset(file) for file in prediction_files]\n",
    "        self.ground_truth_dataset = xr.open_dataset(ground_truth_file)\n",
    "        self.climatology_dataset = xr.open_dataset(climatology_file)\n",
    "        self.era_entire_dataset = xr.open_dataset(entire_era_file)\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        self.save_folder = os.path.join(self.save_dir, prediction_files[0].split('/')[-3])\n",
    "        os.makedirs(self.save_folder, exist_ok=True)\n",
    "        \n",
    "        self.target_variables = list(self.ground_truth_dataset.data_vars)\n",
    "        self.extreme_thresholds = self._calculate_extreme_thresholds()\n",
    "        self.nb_ensemble = len(self.prediction_datasets)\n",
    "\n",
    "    def _calculate_extreme_thresholds(self):\n",
    "        thresholds = {}\n",
    "        for var in self.target_variables:\n",
    "            threshold = self.era_entire_dataset[var].quantile(0.8, dim='time')\n",
    "            thresholds[var] = threshold\n",
    "        return thresholds\n",
    "    \n",
    "    def _replace_time_lt(self, da):\n",
    "        lead_time = np.arange(1, len(da.time) + 1)\n",
    "\n",
    "        # Remplacer la coordonnée time par lead_time\n",
    "        da_new = da.assign_coords(lead_time=('time', lead_time)).swap_dims({'time': 'lead_time'})\n",
    "        da_new = da_new.drop_vars('time')\n",
    "        return da_new\n",
    "    \n",
    "    def calculate_skill_scores(self,ensemble_score, climatology_score, valid_samples):\n",
    "        \"\"\"\n",
    "        Calcule le Skill Score (RPSS ou BSS) à partir des scores de l'ensemble et de la climatologie.\n",
    "        \n",
    "        :param ensemble_score: Score de l'ensemble (RPS ou BS)\n",
    "        :param climatology_score: Score de la climatologie (RPS ou BS)\n",
    "        :param valid_samples: Masque des échantillons valides\n",
    "        :return: Skill Score (RPSS ou BSS)\n",
    "        \"\"\"\n",
    "        # Ajouter une petite valeur à climatology_score pour éviter la division par zéro\n",
    "        epsilon = 1e-10\n",
    "        climatology_score_safe = climatology_score + epsilon\n",
    "        \n",
    "        # Calculer le Skill Score\n",
    "        skill_score = 1 - (ensemble_score / climatology_score_safe)\n",
    "        \n",
    "        # Gérer les cas spéciaux\n",
    "        skill_score = xr.where(skill_score < -1, -1, skill_score)  # Limiter le score minimum à -1\n",
    "        skill_score = xr.where((ensemble_score == 0) & (climatology_score == 0), 0, skill_score)  # Score de 0 si les deux sont zéro\n",
    "        \n",
    "        # Appliquer le masque des échantillons valides\n",
    "        skill_score = skill_score.where(valid_samples > 0)\n",
    "        \n",
    "        return skill_score\n",
    "    \n",
    "    def calculate_scores(self):\n",
    "        self.rpss = {var: [] for var in self.target_variables}\n",
    "        self.brier_scores_ensemble = {var: [] for var in self.target_variables}\n",
    "        self.brier_scores_climatology = {var: [] for var in self.target_variables}\n",
    "        \n",
    "        for var in self.target_variables:\n",
    "            rps_ensemble = 0\n",
    "            rps_climatology = 0\n",
    "            valid_samples = 0\n",
    "            bs_ensemble = 0\n",
    "            bs_climatology = 0\n",
    "                \n",
    "            for sample in range(len(self.ground_truth_dataset.sample)):\n",
    "                truth = self.ground_truth_dataset[var].isel(sample=sample)\n",
    "                clim = self.climatology_dataset[var].isel(sample=sample)\n",
    "                \n",
    "                preds = [pred_dataset[var].isel(sample=sample) for pred_dataset in self.prediction_datasets]\n",
    "                \n",
    "                truth_valid = truth.dropna(dim='time', how='all')\n",
    "                clim_valid = clim.dropna(dim='time', how='all')\n",
    "                preds_valid = [pred.dropna(dim='time', how='all') for pred in preds]\n",
    "                \n",
    "                if len(truth_valid) == 0:\n",
    "                    continue\n",
    "\n",
    "                sample_dates = truth_valid.time.values\n",
    "                # remplacer time par lead time :\n",
    "\n",
    "                truth_valid = self._replace_time_lt(truth_valid)\n",
    "                clim_valid = self._replace_time_lt(clim_valid)\n",
    "                preds_valid = [self._replace_time_lt(pred) for pred in preds_valid]\n",
    "                \n",
    "                categories = self._calculate_historical_categories(var, sample_dates)\n",
    "                \n",
    "                prob_ensemble = self._calculate_ensemble_probabilities(preds_valid, categories)\n",
    "                prob_climatology = self._calculate_probabilities(clim_valid, categories)\n",
    "                obs_categorical = self._categorize_observations(truth_valid, categories)\n",
    "\n",
    "                threshold = self.extreme_thresholds[var]\n",
    "                # Calcul des probabilités d'événements extrêmes pour l'ensemble\n",
    "                prob_extreme_ensemble = (xr.concat(preds_valid, dim='ensemble') > threshold).mean(dim=['ensemble'])\n",
    "                \n",
    "                # Calcul des probabilités d'événements extrêmes pour la climatologie\n",
    "                prob_extreme_climatology = (clim_valid > threshold).astype(int)\n",
    "                \n",
    "                # Observations des événements extrêmes\n",
    "                obs_extreme = (truth_valid > threshold).astype(int)\n",
    "                \n",
    "                bs_ensemble += self._calculate_brier_score(prob_extreme_ensemble, obs_extreme)\n",
    "                bs_climatology += self._calculate_brier_score(prob_extreme_climatology, obs_extreme)\n",
    "                \n",
    "                rps_ensemble += self._calculate_rps(prob_ensemble, obs_categorical)\n",
    "                rps_climatology += self._calculate_rps(prob_climatology, obs_categorical)\n",
    "                valid_samples += 1\n",
    "\n",
    "            rpss = self.calculate_skill_scores(rps_ensemble, rps_climatology, valid_samples)\n",
    "            bss = self.calculate_skill_scores(bs_ensemble, bs_climatology, valid_samples)\n",
    "            self.save_scores(var, rpss, bss)\n",
    "            self.plot_rpss_maps(var,rpss,bss)\n",
    "\n",
    "    def _calculate_ensemble_probabilities(self, preds, categories):\n",
    "        probs = [self._calculate_probabilities(pred, categories) for pred in preds]\n",
    "        return sum(probs) / len(probs)\n",
    "\n",
    "    def _calculate_brier_score(self, forecast_probabilities, observations):\n",
    "        return ((forecast_probabilities - observations) ** 2)\n",
    "    \n",
    "    def _calculate_probabilities(self, data, categories):\n",
    "        quantile_0 = categories.isel(quantile=0)\n",
    "        quantile_1 = categories.isel(quantile=1)\n",
    "        \n",
    "        below = (data <= quantile_0)\n",
    "        middle = (data > quantile_0) & (data <= quantile_1)\n",
    "        above = (data > quantile_1)\n",
    "        middle = middle.assign_coords(quantile= 0.5)\n",
    "        \n",
    "        probs = xr.concat([below, middle, above], dim=pd.Index(['below', 'middle', 'above'], name='category'))\n",
    "        return probs\n",
    "\n",
    "    def _categorize_observations(self, observations, categories):\n",
    "        below = (observations <= categories.isel(quantile=0)).astype(int)\n",
    "        middle = ((observations > categories.isel(quantile=0)) & (observations <= categories.isel(quantile=1))).astype(int)\n",
    "        above = (observations > categories.isel(quantile=1)).astype(int)\n",
    "        middle = middle.assign_coords(quantile= 0.5)\n",
    "        \n",
    "        probs = xr.concat([below, middle, above], dim=pd.Index(['below', 'middle', 'above'], name='category'))\n",
    "        return probs\n",
    "\n",
    "    def _calculate_rps(self, forecast_probabilities, obs_probabilities):\n",
    "        cumulative_forecast = forecast_probabilities.cumsum(dim='category')\n",
    "        cumulative_obs = obs_probabilities.cumsum(dim='category')\n",
    "        return ((cumulative_forecast - cumulative_obs) ** 2).mean(dim='category')\n",
    "    \n",
    "    def _calculate_historical_categories(self, var, sample_dates):\n",
    "        historical_data = []\n",
    "        seen_times = set()\n",
    "\n",
    "        for date in sample_dates:\n",
    "            pd_date = pd.Timestamp(date)\n",
    "            same_day_month_samples = self.ground_truth_dataset[var].sel(\n",
    "                time=self.ground_truth_dataset.time.dt.dayofyear == pd_date.dayofyear\n",
    "            )\n",
    "            for sample_idx in range(len(same_day_month_samples.sample)):\n",
    "                sample_data = same_day_month_samples.isel(sample=sample_idx)\n",
    "                sample_data_non_nan = sample_data.dropna(dim='time', how='all')\n",
    "                sample_times = set(sample_data_non_nan.time.values)\n",
    "\n",
    "                new_times = sample_times - seen_times\n",
    "                if new_times:\n",
    "                    seen_times.update(new_times)  # Mettre à jour les dates vues\n",
    "                    historical_data.append(sample_data_non_nan.sel(time=list(new_times)))\n",
    "\n",
    "        if historical_data:\n",
    "            historical_data = xr.concat(historical_data, dim='time')\n",
    "            terciles = historical_data.quantile([0.3333, 0.6667], dim='time')\n",
    "\n",
    "            return terciles\n",
    "        else:\n",
    "            return xr.DataArray(np.nan, dims=['quantile', 'lat', 'lon'], coords={'quantile': [0.3333, 0.6667]})\n",
    "        \n",
    "    def plot_rpss_maps(self, var , rpss, bss):\n",
    "        # plot rpss \n",
    "        rpss_mean = rpss.mean(dim='lead_time')\n",
    "        \n",
    "        lats = [30] + list(rpss_mean.latitude.values) + [45]\n",
    "        lons = [-10] + list(rpss_mean.longitude.values) + [40]\n",
    "\n",
    "        # Créer la carte\n",
    "        fig, ax = plt.subplots(figsize=(12, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "        \n",
    "        # Utiliser pcolormesh au lieu de imshow pour une meilleure représentation des données discrètes\n",
    "        im = ax.imshow(rpss_mean, cmap=\"RdYlBu\", transform=ccrs.PlateCarree(),\n",
    "                           extent=[lons[0], lons[-1], lats[0], lats[-1]], vmin=-1, vmax=1)\n",
    "        \n",
    "        # Ajouter les caractéristiques de la carte\n",
    "        ax.coastlines(resolution='50m', color='black', linewidth=0.5)\n",
    "        ax.add_feature(cfeature.BORDERS, linestyle=':', color='black', linewidth=0.5)\n",
    "        ax.add_feature(cfeature.LAND, edgecolor='black', facecolor='lightgrey', alpha=0.3)\n",
    "        ax.add_feature(cfeature.OCEAN, edgecolor='black', facecolor='lightblue', alpha=0.3)\n",
    "        \n",
    "        # Configurer la grille\n",
    "        gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                        linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "        lat_margin = 0.5  # ajustez selon vos besoins\n",
    "        ax.set_extent([rpss_mean.longitude.min(), rpss_mean.longitude.max(),\n",
    "                    rpss_mean.latitude.min() - lat_margin, rpss_mean.latitude.max() + lat_margin], \n",
    "                    crs=ccrs.PlateCarree())\n",
    "        gl.xlocator = mticker.FixedLocator(np.arange(lons[0], lons[-1], 10))\n",
    "        gl.ylocator = mticker.FixedLocator(np.arange(lats[0], lats[-1], 5))\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        \n",
    "        # Ajouter la barre de couleur\n",
    "        cbar = plt.colorbar(im, ax=ax, orientation='horizontal', pad=0.08)\n",
    "        cbar.set_label(f'RPSS - {var}', fontsize=12)\n",
    "        \n",
    "        # Configurer le titre et les limites de la carte\n",
    "        plt.title(f'Mean RPSS - {var} - {self.nb_ensemble} ensemble ', fontsize=16)\n",
    "        ax.set_extent([lons[0], lons[-1], lats[0], lats[-1]], crs=ccrs.PlateCarree())\n",
    "        \n",
    "        # Sauvegarder la figure\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.save_folder, f'{var}_rpss_map.png'), \n",
    "                    bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        bss_mean = bss.mean(dim='lead_time')\n",
    "        lats = [30] + list(bss_mean.latitude.values) + [45]\n",
    "        lons = [-10] + list(bss_mean.longitude.values) + [40]\n",
    "\n",
    "        # Créer la carte\n",
    "        fig, ax = plt.subplots(figsize=(12, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "        \n",
    "        # Utiliser pcolormesh au lieu de imshow pour une meilleure représentation des données discrètes\n",
    "        im = ax.imshow(bss_mean, cmap='RdYlBu', transform=ccrs.PlateCarree(),\n",
    "                           extent=[lons[0], lons[-1], lats[0], lats[-1]], vmin=-1, vmax=1)\n",
    "        \n",
    "        # Ajouter les caractéristiques de la carte\n",
    "        ax.coastlines(resolution='50m', color='black', linewidth=0.5)\n",
    "        ax.add_feature(cfeature.BORDERS, linestyle=':', color='black', linewidth=0.5)\n",
    "        ax.add_feature(cfeature.LAND, edgecolor='black', facecolor='lightgrey', alpha=0.3)\n",
    "        ax.add_feature(cfeature.OCEAN, edgecolor='black', facecolor='lightblue', alpha=0.3)\n",
    "        \n",
    "        # Configurer la grille\n",
    "        gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                        linewidth=0.5, color='gray', alpha=0.5, linestyle='--')\n",
    "        gl.xlocator = mticker.FixedLocator(np.arange(lons[0], lons[-1], 10))\n",
    "        gl.ylocator = mticker.FixedLocator(np.arange(lats[0], lats[-1], 5))\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        \n",
    "        # Ajouter la barre de couleur\n",
    "        cbar = plt.colorbar(im, ax=ax, orientation='horizontal', pad=0.08)\n",
    "        cbar.set_label(f'bss - {var}', fontsize=12)\n",
    "        \n",
    "        # Configurer le titre et les limites de la carte\n",
    "        plt.title(f'Mean BSS (80th centile) - {var}- {self.nb_ensemble} ensemble', fontsize=16)\n",
    "        ax.set_extent([lons[0], lons[-1], lats[0], lats[-1]], crs=ccrs.PlateCarree())\n",
    "        \n",
    "        # Sauvegarder la figure\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.save_folder, f'{var}_bss_map.png'), \n",
    "                    bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    def save_scores(self, var, rpss, bss):\n",
    "        rpss.name = f'{var}_rpss'\n",
    "        bss.name = f'{var}_bss'\n",
    "        \n",
    "        # Sauvegarder les scores complets (avec toutes les dimensions)\n",
    "        rpss.to_netcdf(os.path.join(self.save_folder, f'{var}_rpss.nc'))\n",
    "        bss.to_netcdf(os.path.join(self.save_folder, f'{var}_bss.nc'))\n",
    "        \n",
    "        # Calculer et sauvegarder les moyennes spatiales\n",
    "        rpss_mean = rpss.mean(dim=['latitude', 'longitude'])\n",
    "        bss_mean = bss.mean(dim=['latitude', 'longitude'])\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'lead_time': rpss.lead_time.values,\n",
    "            f'{var}_rpss': rpss_mean.values,\n",
    "            f'{var}_bss': bss_mean.values\n",
    "        })\n",
    "        \n",
    "        df.to_csv(os.path.join(self.save_folder, f'{var}_scores.csv'), index=False)\n",
    "        \n",
    "        print(f\"Scores for {var} saved successfully.\")\n",
    "\n",
    "# Usage remains the same\n",
    "\n",
    "save_folder = './evaluation_results'\n",
    "\n",
    "\n",
    "evaluator = ModelEvaluation(prediction_files, ground_truth_file, climatology_file, save_folder, entire_era_file)\n",
    "evaluator.calculate_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "extreme_events_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
